{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42eb74d0",
   "metadata": {},
   "source": [
    "# homework 8\n",
    "\n",
    "(finally)\n",
    "\n",
    "## Question 1\n",
    "apply k-means and hierarchical clustering to the ORLface dataset. set k=2 in k-means and select 2 clusters in hierarchical clustering. do the clustering results match the two gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd7540",
   "metadata": {},
   "source": [
    "First, we load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d357246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2576)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "data = []\n",
    "for i in range(1, 41):\n",
    "    for j in range(1,11):\n",
    "        image_dir = f\"C:/Users/user/Desktop/ORL faces/{i}_{j}.png\"\n",
    "        img = Image.open(image_dir)\n",
    "        img_array = np.asarray(img)\n",
    "        data.append(img_array.flatten())\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a3bdd",
   "metadata": {},
   "source": [
    "then, we use k-means to proceed data. We assume that the bigger group is group 1(man), and the smaller group is group 0 (woman)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5747ad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=622)\n",
    "kmeans.fit(data)\n",
    "kmeans_labels = kmeans.labels_\n",
    "count0 = list(kmeans_labels).count(0)\n",
    "count1 = list(kmeans_labels).count(1)\n",
    "if count0 > count1:\n",
    "    num = 0\n",
    "    for i in kmeans.labels:\n",
    "        if i == 0:\n",
    "            kmeans.labels[num] = 1\n",
    "        else:\n",
    "            kmeans.labels[num] = 0\n",
    "        num += 1\n",
    "\n",
    "count0 = list(kmeans_labels).count(0)\n",
    "count1 = list(kmeans_labels).count(1)\n",
    "print(count0)\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a63b0ab",
   "metadata": {},
   "source": [
    "We can see the labels in 0 and 1 are balance, which are not we expected, but OK. \n",
    "Then, we use hierarchical clustering and do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02917699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "hierarchical = AgglomerativeClustering(n_clusters=2)\n",
    "hierarchical.fit(data)\n",
    "hierarchical_labels = hierarchical.labels_\n",
    "\n",
    "count0 = list(hierarchical_labels).count(0)\n",
    "count1 = list(hierarchical_labels).count(1)\n",
    "if count0 > count1:\n",
    "    num = 0\n",
    "    for i in hierarchical_labels:\n",
    "        if i == 0:\n",
    "            hierarchical_labels[num] = 1\n",
    "        else:\n",
    "            hierarchical_labels[num] = 0\n",
    "        num += 1\n",
    "count0 = list(hierarchical_labels).count(0)\n",
    "count1 = list(hierarchical_labels).count(1)\n",
    "print(count0)\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c897b",
   "metadata": {},
   "source": [
    "We found that the label 0 and label 1 are balanced, too.\n",
    "Let apply the trye labels and see the result of some indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e19868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = [0,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1]\n",
    "true_labels = []\n",
    "for i in gender:\n",
    "    for _ in range(10):\n",
    "        true_labels.append(i)\n",
    "true_labels = np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99537f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics for K-means Clustering:\n",
      "ARI: -0.0021\n",
      "NMI: 0.0378\n",
      "\n",
      "Evaluation metrics for Hierarchical Clustering:\n",
      "ARI: -0.0002\n",
      "NMI: 0.0062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "# Calculate the evaluation metrics for k-means clustering\n",
    "kmeans_ari = adjusted_rand_score(true_labels, kmeans_labels)\n",
    "kmeans_nmi = normalized_mutual_info_score(true_labels, kmeans_labels)\n",
    "\n",
    "# Calculate the evaluation metrics for hierarchical clustering\n",
    "hierarchical_ari = adjusted_rand_score(true_labels, hierarchical_labels)\n",
    "hierarchical_nmi = normalized_mutual_info_score(true_labels, hierarchical_labels)\n",
    "\n",
    "print(\"Evaluation metrics for K-means Clustering:\")\n",
    "print(\"ARI: {:.4f}\".format(kmeans_ari))\n",
    "print(\"NMI: {:.4f}\".format(kmeans_nmi))\n",
    "print()\n",
    "\n",
    "print(\"Evaluation metrics for Hierarchical Clustering:\")\n",
    "print(\"ARI: {:.4f}\".format(hierarchical_ari))\n",
    "print(\"NMI: {:.4f}\".format(hierarchical_nmi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c3efb",
   "metadata": {},
   "source": [
    "The Adjusted Rand Index (ARI) measures the similarity between two clusterings, taking into account all pairs of samples and their labels. It returns a value between -1 and 1, where a higher value indicates better agreement between the clustering and true labels. The Normalized Mutual Information (NMI) measures the mutual information between two clusterings, normalized by the entropy of the clusterings. It also returns a value between 0 and 1, with a higher value indicating better agreement.\n",
    "\n",
    "By comparing the ARI and NMI values for both k-means clustering and hierarchical clustering, you can assess their performance and determine which method gives better results for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc21b7",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "drop the origin variable from AUTOMPG and apply k-means. hierarchical clustering, and DBSCAN to the AUTOMPG dataset. Check if the clustering result match the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eef3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of 1:  245\n",
      "no. of 2:  68\n",
      "no. of 3:  79\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = pd.read_csv(\"C:/Users/user/Desktop/autompg.csv\")\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "X = data.iloc[:, :-2] # -1 is car_name\n",
    "y = data.iloc[:, -2]\n",
    "\n",
    "print(\"no. of 1: \", list(y).count(1))\n",
    "print(\"no. of 2: \", list(y).count(2))\n",
    "print(\"no. of 3: \", list(y).count(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c38c6",
   "metadata": {},
   "source": [
    "We first apply StandardScaler, and fit three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a4a8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans_labels = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "hierarchical = AgglomerativeClustering(n_clusters=3)\n",
    "hierarchical_labels = hierarchical.fit_predict(scaled_data)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726a673",
   "metadata": {},
   "source": [
    "I want to decide which labels the models gave are american cars, japanese cars, and so on. Therefore, I test six combinations and see which are the most possible combinations. We use accuracy scores to decide how to sequence the datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e41bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 利用accuracy scores來決定123怎麼排\n",
    "k_means_best_accuracy = 0\n",
    "k_means_best_mapping = None\n",
    "\n",
    "for mapping in [{0: 1, 1: 2, 2: 3}, {0: 1, 1: 3, 2: 2}, {0: 2, 1: 1, 2: 3},{0: 2, 1: 3, 2: 1},{0: 3, 1: 1, 2: 2},{0: 3, 1: 2, 2: 1}]:\n",
    "    kmeans_predicted_labels = np.array([mapping[label] for label in kmeans_labels])\n",
    "    kmeans_accuracy = accuracy_score(y, kmeans_predicted_labels)\n",
    "    if kmeans_accuracy > k_means_best_accuracy:\n",
    "        k_means_best_accuracy = kmeans_accuracy\n",
    "        k_means_best_mapping = mapping\n",
    "\n",
    "kmeans_predicted_labels = np.array([k_means_best_mapping[label] for label in kmeans_labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5a8c8",
   "metadata": {},
   "source": [
    "We use the same notion to map the hierarchical, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "541b3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_best_accuracy = 0\n",
    "hierarchical_best_mapping = None\n",
    "\n",
    "for mapping in [{0: 1, 1: 2, 2: 3}, {0: 1, 1: 3, 2: 2}, {0: 2, 1: 1, 2: 3},{0: 2, 1: 3, 2: 1},{0: 3, 1: 1, 2: 2},{0: 3, 1: 2, 2: 1}]:\n",
    "    hierarchical_predicted_labels = np.array([mapping[label] for label in hierarchical_labels])\n",
    "    hierarchical_accuracy = accuracy_score(y, hierarchical_predicted_labels)\n",
    "    if hierarchical_accuracy > hierarchical_best_accuracy:\n",
    "        hierarchical_best_accuracy = hierarchical_accuracy\n",
    "        hierarchical_best_mapping = mapping\n",
    "\n",
    "hierarchical_predicted_labels = np.array([hierarchical_best_mapping[label] for label in hierarchical_labels])\n",
    "# print(hierarchical_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be88c7f",
   "metadata": {},
   "source": [
    "We use the same notion to map the DBSCAN, too. IF the dbscan model give use -1 or 3, we alter them too 1, which are the biggest part of the origin of AUTOmpg dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "700d0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_best_accuracy = 0\n",
    "dbscan_best_mapping = None\n",
    "\n",
    "for mapping in [{-1: 1,3: 1, 0: 1, 1: 2, 2: 3}, {-1: 1,3: 1, 0: 1, 1: 3, 2: 2}, {-1: 1,3: 1, 0: 2, 1: 1, 2: 3},{-1: 1,3: 1, 0: 2, 1: 3, 2: 1},{-1: 1,3: 1, 0: 3, 1: 1, 2: 2},{-1: 1,3: 1, 0: 3, 1: 2, 2: 1}]:\n",
    "    dbscan_predicted_labels = np.array([mapping[label] for label in dbscan_labels])\n",
    "    dbscan_accuracy = accuracy_score(y, dbscan_predicted_labels)\n",
    "    if dbscan_accuracy > dbscan_best_accuracy:\n",
    "        dbscan_best_accuracy = dbscan_accuracy\n",
    "        dbscan_best_mapping = mapping\n",
    "\n",
    "dbscan_predicted_labels = np.array([dbscan_best_mapping[label] for label in dbscan_labels])\n",
    "# print(dbscan_predicted_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1c568",
   "metadata": {},
   "source": [
    "We now see the accuracy score, and we can see all of them perform very bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca8f71c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_means_best_accuracy 0.45153061224489793\n",
      "hierarchical_best_accuracy 0.45408163265306123\n",
      "dbscan_best_accuracy 0.4770408163265306\n"
     ]
    }
   ],
   "source": [
    "print(\"k_means_best_accuracy\", k_means_best_accuracy)\n",
    "print(\"hierarchical_best_accuracy\", hierarchical_best_accuracy)\n",
    "print(\"dbscan_best_accuracy\", dbscan_best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755dd15c",
   "metadata": {},
   "source": [
    "I make a dataframe to see how the labels are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "affb665a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     true  kmeans  hierarchical  dbscan\n",
      "0       1       1             1       1\n",
      "1       1       1             1       1\n",
      "2       1       1             1       1\n",
      "3       1       1             1       1\n",
      "4       1       1             1       1\n",
      "..    ...     ...           ...     ...\n",
      "393     1       3             3       3\n",
      "394     2       3             3       1\n",
      "395     1       3             3       3\n",
      "396     1       3             3       3\n",
      "397     1       3             3       3\n",
      "\n",
      "[392 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "dic = {\"true\":y, \"kmeans\":kmeans_predicted_labels, \"hierarchical\":hierarchical_predicted_labels, \"dbscan\":dbscan_predicted_labels}\n",
    "comparison = pd.DataFrame(dic)\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e0f5a",
   "metadata": {},
   "source": [
    "When we compare these result with supervised models, we can see our predictions are not precise at all in unsupervised learning methods. Here are some possible reason.\n",
    "\n",
    "1. Labeled Data: Supervised learning relies on labeled data, which provides explicit guidance to the model, allowing it to learn patterns and relationships more effectively.\n",
    "\n",
    "2. Exploiting Known Patterns: Supervised learning models are explicitly trained to recognize and exploit the patterns present in the labeled data, leading to more accurate predictions.\n",
    "\n",
    "3. Evaluating Model Performance: Supervised learning methods can be evaluated using metrics that provide quantitative measures of performance, facilitating iterative improvement.\n",
    "\n",
    "4. Task-Specific Optimization: Supervised learning methods are designed to solve specific tasks, allowing for fine-tuning and better performance optimization.\n",
    "\n",
    "5. Bias Reduction: Supervised learning with diverse labeled data helps mitigate biases and improves generalization across different instances.\n",
    "\n",
    "I think the reason 1 and 2 are the most important reasons for the result we observed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
