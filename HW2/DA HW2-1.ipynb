{"cells":[{"cell_type":"markdown","source":["I will type result participation at the top of every block of code, and type the discussion part at the bottom of each set of problem. \n","First, I import necessary package and mount my google drive in order to get access to the ORL faces folder. PIL package is used for preprocessing the ORL faces photos.\n","\n"],"metadata":{"id":"k04ZqI56EC7e"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24830,"status":"ok","timestamp":1678581151139,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"},"user_tz":-480},"id":"eIVLCh7EsP2U","outputId":"0998b043-51a5-4637-f8db-ab9d1b8183c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Question 1-1:\n","\n","First, the gender part was specificly marked by ourselves. As teacher said, as regression was a supervised learning model, we need to label the photos by yourself in this homework and see if a regression model works.\n","\n","Then, we read each of the photos and transpose them into matrices. A 46*56 definition photo can turn into a matrices with 2576 values, each value represents the brightness of that point, since those photos are black-white photos.\n","\n","Finally, we flatten each photos to make the 2D matrices one-dimension. Although this step might make the photos lost its directionality, but it will be easier to analyze and demostrate.\n","\n","We have 400 photos, each photo have 2576 spots. So we have a 2D ndarray (400x2576) matrix. We will use it to make linear regression.\n","\n"],"metadata":{"id":"7D9jWikqLT2h"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZM8f6FOZZb5f"},"outputs":[],"source":["gender = [0,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1]\n","data = []\n","for i in range(1, 41):\n","    for j in range(1,11):\n","        image_dir = f\"/content/drive/MyDrive/ORL Faces/{i}_{j}.png\"\n","        img = Image.open(image_dir)\n","        img_array = np.asarray(img)\n","        img_array = np.append(img_array, gender[i-1])\n","        data.append(img_array.flatten())\n","data = np.array(data)"]},{"cell_type":"markdown","source":["Let's check the shape of this matrix!"],"metadata":{"id":"XeUe-ptWLgS4"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":432,"status":"ok","timestamp":1678581511509,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"},"user_tz":-480},"id":"mmKW-iWtcUvP","outputId":"c00e0c96-90e3-4366-f7ae-211a328c1acc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(400, 2576)"]},"metadata":{},"execution_count":3}],"source":["data[:,:-1].shape"]},{"cell_type":"markdown","source":["Question 1-2:\n","\n","We try to use linear regression to find the best parameters of the matrix to describe. We use the linear regression method. Data[:,:-1] means the brightness points of each picture, and data[:,-1] means the gender of each picture, which is output of each inputs.\n","\n","Although the code give us seemingly nice one intercept and 2576 coefficient, we have to look into to result to chech whether the answer is valid or not.\n","\n","From the perspective of linear algebra, we find that it is unable to calculate A^TA inverse, which means the answer of this matrix should be no solutions. From the perspective of high school math, we found that we use 2576 parameter(a0+a1x1+a2x2...+anxn), while the restrictive(限制式) are only 400. \n","\n","It implies that the answer of paramters will be infinitely many. Therefore, although we can see a set of intercept and coefficient to describe the matrix, it is of no use, since there are infinite solution to this problem."],"metadata":{"id":"I7tf6qcsLmVa"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1663,"status":"ok","timestamp":1678581515438,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"},"user_tz":-480},"id":"C3L64e1lZfxD","outputId":"2fc27453-53d8-4d49-b717-c0c74e9687a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["intercept: 0.8096839954559842\n","coefficient: [ 8.39916784e-05  1.08459706e-04  1.07400070e-04 ... -4.26834929e-05\n"," -1.90141989e-04 -1.65655457e-04]\n","0.00037564741414733167\n"]}],"source":["from sklearn.linear_model import LinearRegression\n","model = LinearRegression(fit_intercept=True)\n","model.fit(data[:,:-1],data[:, -1])\n","print('intercept:',model.intercept_)\n","print('coefficient:',model.coef_)\n","print(max(model.coef_)) # 用公式解(ALG) ATA inverse算不出來 會有無限多組解 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5462,"status":"ok","timestamp":1678514722941,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"},"user_tz":-480},"id":"F--_-t7FuAv5","outputId":"65d017e8-901a-4208-a895-c38b1dd0a021"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n"]}],"source":["pip install -U scikit-learn"]},{"cell_type":"markdown","source":["Question 1-3:\n","\n","perform the stepwise regression label from a null model to find the important pixels.\n","\n","In any phenomenon, there will be certain factors that play a bigger role in determining an outcome. In simple terms, stepwise regression is a process that helps determine which factors are important and which are not. Certain variables have a rather high p-value and were not meaningfully contributing to the accuracy of our prediction. From there, only important factors are kept to ensure that the linear model does its prediction based on factors that can help it produce the most accurate result.(quote from Ryan Kwok's medium. reference: https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922)\n","\n","Therefore, our work is to find some points that matter most to recognize a photo. The first three sentences are extra code to prevent the unepected errors. We majorly use SequentialFeatureSelector to find the most important pixels. \n","\n","In this model, we set max iterarions to be 1000, but the process will end before this number. K_features mean how many important pixels should the model choose, we set 10, since I found out that after 10 pixels, the score will remain on 99.5% and will not be lifted phenomenally. Forward=True means that we use a null model first, and we add the most important points to best describe the datas. If it was false, it will be the opposite: the model will conclude all of the pixels, and we try to delete the less important pixels. We use the former because of what problem demands."],"metadata":{"id":"b8mxiAsXOGi9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6Co8k0qsoXO","outputId":"67aa9fc4-47d2-4fd6-f889-0e048ad5c888","executionInfo":{"status":"ok","timestamp":1678582068002,"user_tz":-480,"elapsed":419071,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2576 out of 2576 | elapsed:   18.2s finished\n","\n","[2023-03-12 00:41:07] Features: 1/10 -- score: 0.9025[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2575 out of 2575 | elapsed:   27.0s finished\n","\n","[2023-03-12 00:41:34] Features: 2/10 -- score: 0.9475[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2574 out of 2574 | elapsed:   29.7s finished\n","\n","[2023-03-12 00:42:04] Features: 3/10 -- score: 0.9725[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2573 out of 2573 | elapsed:   35.1s finished\n","\n","[2023-03-12 00:42:39] Features: 4/10 -- score: 0.9775[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2572 out of 2572 | elapsed:   38.3s finished\n","\n","[2023-03-12 00:43:18] Features: 5/10 -- score: 0.9825[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2571 out of 2571 | elapsed:   41.9s finished\n","\n","[2023-03-12 00:44:00] Features: 6/10 -- score: 0.985[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2570 out of 2570 | elapsed:   33.0s finished\n","\n","[2023-03-12 00:44:33] Features: 7/10 -- score: 0.99[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2569 out of 2569 | elapsed:   60.0s finished\n","\n","[2023-03-12 00:45:33] Features: 8/10 -- score: 0.9925[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done 2568 out of 2568 | elapsed:   56.2s finished\n","\n","[2023-03-12 00:46:30] Features: 9/10 -- score: 0.995[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"]},{"output_type":"stream","name":"stdout","text":["[2, 99, 134, 318, 440, 446, 600, 1932, 2164, 2208]\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done 2567 out of 2567 | elapsed:  1.3min finished\n","\n","[2023-03-12 00:47:47] Features: 10/10 -- score: 0.995"]}],"source":["import joblib\n","import sys\n","sys.modules['sklearn.externals.joblib'] = joblib\n","from mlxtend.feature_selection import SequentialFeatureSelector\n","from sklearn import linear_model\n","\n","df = pd.DataFrame(data)\n","X = df.iloc[:, :-1]\n","y = df.iloc[:,-1]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","sfs = SequentialFeatureSelector(linear_model.LogisticRegression(max_iter=1000),\n","                                k_features=10,\n","                                forward=True,\n","                                scoring='accuracy',\n","                                verbose = 2,\n","                                cv=None)\n","sfs.fit(X_train, y_train)\n","feature = list(forward.k_feature_names_)\n","print(feature)"]},{"cell_type":"markdown","source":["Lastly, we use matplotlib to visualize the problem. We first a 46x56 canva, than put the result pixelss on it. We can see where are the most important pixels. \n","\n","They are mainly on the upper-right part and middle-bottem part of the photos to determain whether the person in the photos is a man or a woman."],"metadata":{"id":"TCdoYe6JQyqV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"executionInfo":{"elapsed":477,"status":"ok","timestamp":1678582179205,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"},"user_tz":-480},"id":"T6tN7Tm46qU7","outputId":"27c461ca-0c16-4407-84a8-a346b9de9ecf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","plt.imshow(np.zeros((46, 56)), cmap=\"copper\")\n","plt.scatter([num % 56 for num in feature],[num // 56 for num in feature], c=\"blue\", s=50)\n","plt.show()"]},{"cell_type":"markdown","source":["Discussion: \n","1. I think that most of the discussions are demonstrated above, so this part might be a little simplier.\n","2. After seeing the scatterplot, I think the hair and the mouth&jaw will be the main part. The woman hair is more that the man, and at the upper-right part, the man may be no hair, but woman have, because their hair is more and fluffy. Secondly, the man's faces are longer than woman, and they have longer jaws. So, their jaws and mouths will be a bit lower than woman, causing the phenomenon of the output. these output is align to our expectation: some features matter more than other features, and it will form some significant groups.\n","3. In the sfs model, we use LogisticRegression model due to the problem discussed before. From the perspective of LA, we shouldn't use the linear regression, and the sfs model will refuse it, too. So, we use logistic regression and achieve the goal. "],"metadata":{"id":"Hm1LRrCnRsnV"}},{"cell_type":"markdown","source":["Question 2:\n","\n","design an iterative algorithm base on repeating \"multiple regressions\" ro achieve the highest point of the volcano. (the volcano is in New Zealand!) The starting point is at right bottom corner. Although the problem indicate (87,1), but from the perspective of pandas, it should be (86,60), since the beginning is 0, not 1, and the values of x2-axis coordination is increment."],"metadata":{"id":"eVJheghYTqt-"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.linear_model import LinearRegression"],"metadata":{"id":"SVGuVGfl8PaO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There are a lot of discussion of this part.\n","\n","1. How to achieve the highest point of this volcano? I use the method that consider the two coefficient of each iterative turn as the optimization direction. Seeing the hint, we first set the domain size to be 2, which means the domain size is a 5x5 smaller matrix. (we use the existing point as the center of each matrix, and take the surrounding neighbor into account to take into consideration. Centered at the existing point, we extend by 2 of each direction, making it 5x5.)\n","2. sentence 14-18: Based on my observation and the code implies, the output of the coefficients will not be significant enough if the different values (elevations) in the smaller domain matrix are less than three. Therefore, if we found the elevations of that domain matrix are less than three type, we abandon using the linear regression method and just let the existing point move to the upper-left side.\n","3. sentence 30-31: since we use the coefficient to determine the direction, it is possible that the existing point stuck at specific pixels because both coefficients are 0 after we round it. Therefore, we should expand the scale of the domain size to take more pixels into consider, and it might be helpful to escape. It will become more and more large, until the domain reach the border the volcano.csv data.\n","\n","4. sentence 19-26: However, although we largen the scale due to aforementioned reason, it is not good enough - what affect the existing point most should be its neighbor, but when we largen our scale, the effect of these point will be diluted. Therefore, when the domain size reach maximum, we turn the scale back to 2 to check whether it is at the highest point or not. We just need to take these steps one time.\n","\n","5. In conclusion, we use iterative multiple regressions to reach the maximum of the volcano. the X are the locations of each points, and Y are the elevations. "],"metadata":{"id":"HTIE-taYUhLD"}},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Volcano.csv',header=None)  # Read in the volcano.csv file\n","domain_size = 2 # including the point itself (as the center of the domain) and its neighbor 2 blocks of data, forming a 5x5 range.\n","width,length = 60, 86  # the right-bottom corner\n","reach_maximum = 0\n","\n","for i in range(500):\n","    domain = data.iloc[width-domain_size:width+domain_size+1, length-domain_size:length+domain_size+1] # use iloc to form the small domain.\n","    coords = [] # record all of the x1 and x2 of this domain.\n","    for i in range(domain_size*2+1):\n","        for j in range(domain_size*2+1):\n","            coords.append([width-domain_size+i, length-domain_size+j])\n","    elevations = domain.values.reshape(-1,1)  # record all of the values(elevations) in the small dataframe.\n","\n","    if 1 <= len(set(elevations.flatten().tolist())) <= 3 : # if the smaller domain consists of less than three different elevations, just move to upper-left side.\n","        width -= 1 # After moving, we do not need to use the old domain to do the Linear regression, just go to the next new domain.\n","        length -= 1\n","        continue\n","\n","    if len(elevations) == 0: # if the domain size is too large that it reach the border of the whole csv data, reshape the domain size to its original setting.\n","        if reach_maximum == 0: # when too many data are taken into consideration, the features of neighbor elevations of present point will be undermined.\n","            domain_size = 2 # But we just need to reshape it once.\n","            reach_maximum += 1\n","            continue\n","        else:\n","            break\n","\n","    model = LinearRegression().fit(coords, elevations)  # Linear regression with the parameter coordinates and elevations\n","    model.coef_\n","    width += round(model.coef_[0][0])  # We use the coefficients to determine the way the data point should go.\n","    length += round(model.coef_[0][1])\n","    if (-0.5 <model.coef_[0][0] < 0.5) and (-0.5 <model.coef_[0][1] < 0.5):  # if the old regression model can't be optimized, just make the domain_size become larger.\n","        domain_size += 1\n","\n","print(\"latitude: \" + str(width))\n","print(\"lontitude: \" + str(length))\n","print(\"predicted_max_value: \" + str(data.loc[width-1][length-1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"mtz-T0Ex8S45","executionInfo":{"status":"error","timestamp":1678626191342,"user_tz":-480,"elapsed":2075,"user":{"displayName":"Alex Tseng","userId":"16934592860307910732"}},"outputId":"4bb9a7be-3a63-470e-8c6a-851137b08fc6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-00a6442cb087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Volcano.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Read in the volcano.csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdomain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m# including the point itself (as the center of the domain) and its neighbor 2 blocks of data, forming a 5x5 range.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m  \u001b[0;31m# the right-bottom corner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreach_maximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Volcano.csv'"]}]},{"cell_type":"markdown","source":["Discussion:\n","1. we enumerate these two data and use linear regression time by time to find the best point. Finally, the point will Oscillated between (27, 17) (elevation: 184) and (28,20) (elevation: 192), which are very close to the hight point: (31,20) (elevation: 195)."],"metadata":{"id":"lphduR3Qaa35"}},{"cell_type":"markdown","source":["Question 3-1:\n","simulate a multiple regression with two predictors problems by myself, with 50000 samples. \n","\n","y = a0 + a1x1 + a2x2 + epsilon\n","\n","Use the regression package in python to analyze the problem and review the result.\n","\n","First, I set the a0, a1 and a2 manually, and make the x1 and x2 random selected. It obeys the normal distribution. The eplison obeys normal distribution, too. \n","\n","Lastly, we use ols to see the effect of our values.\n","\n","This code simulates a multiple regression problem with two predictors (x1 and x2) and one outcome variable (y), and then fits a linear regression model to the data using the statsmodels library in Python.\n","\n","The outcome of the code includes:\n","\n","The simulation of the data: The first few lines of the code simulate the data by setting the stable parameters a0, a1, and a2 to 1.5, 2.5, and 0.5, respectively, and generating random normal variables for x1, x2, and epsilon using np.random.normal() function.\n","\n","Creating a DataFrame: The generated x1, x2, and y variables are then combined into a Pandas DataFrame called data.\n","\n","Fitting a linear regression model: The next line of code fits a linear regression model to the data using the sm.formula.ols() function from the statsmodels library. The model is specified using a formula y ~ x1 + x2, which means that the outcome variable y is being regressed on the two predictor variables x1 and x2. The fit() function then fits the model to the data and returns the fitted model object, which is assigned to the variable model.\n","\n","Printing the model summary: The last line of code prints the summary of the fitted model using the summary() function. The summary provides information about the goodness of fit of the model, as well as the estimated coefficients for the intercept (a0) and the two predictors (a1 and a2). It also provides various statistical measures, such as the R-squared, F-statistic, and p-values, to evaluate the significance of the predictors in the model.\n","\n","Overall, the code generates a simulated dataset and fits a linear regression model to it. The outcome of the model summary provides information about the relationship between the predictor variables and the outcome variable, as well as the overall fit of the model to the data."],"metadata":{"id":"rqxtIcxMahWp"}},{"cell_type":"code","source":["import statsmodels.api as sm\n","np.random.seed(42)\n","a0 = 1.5 # set the stable parameters a0, a1 and a2.\n","a1 = 2.5\n","a2 = 0.5\n","x1 = np.random.normal(0, 1, 50000)  # x1, x2 and eplison will not be stable.\n","x2 = np.random.normal(0, 1, 50000)\n","epsilon = np.random.normal(0, 1, 50000)\n","y = a0 + a1*x1 + a2*x2 + epsilon\n","data = pd.DataFrame({'y': y, 'x1': x1, 'x2': x2})\n","print(data)\n","model = sm.formula.ols('y ~ x1 + x2', data=data).fit() # to see the effect of our values\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8X6iU3Wd8WX6","executionInfo":{"status":"ok","timestamp":1678559542262,"user_tz":-480,"elapsed":2545,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"aac555b3-a4b4-4f5f-d751-e6f33f5f282c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              y        x1        x2\n","0      3.821483  0.496714  0.098206\n","1     -0.033070 -0.138264 -0.064108\n","2      4.170554  0.647689  0.951791\n","3      5.454752  1.523030  1.532831\n","4      0.930637 -0.234153  0.686847\n","...         ...       ...       ...\n","49995  2.308428  0.056799 -0.225225\n","49996  1.345569 -0.024923 -0.569778\n","49997  2.776568  0.500085  0.409185\n","49998  2.209081  0.265215 -0.211092\n","49999  6.117419  1.515811  0.120063\n","\n","[50000 rows x 3 columns]\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.867\n","Model:                            OLS   Adj. R-squared:                  0.867\n","Method:                 Least Squares   F-statistic:                 1.627e+05\n","Date:                Sat, 11 Mar 2023   Prob (F-statistic):               0.00\n","Time:                        18:32:22   Log-Likelihood:                -70924.\n","No. Observations:               50000   AIC:                         1.419e+05\n","Df Residuals:                   49997   BIC:                         1.419e+05\n","Df Model:                           2                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","Intercept      1.5036      0.004    336.346      0.000       1.495       1.512\n","x1             2.5029      0.004    559.962      0.000       2.494       2.512\n","x2             0.5049      0.004    113.122      0.000       0.496       0.514\n","==============================================================================\n","Omnibus:                        0.719   Durbin-Watson:                   1.986\n","Prob(Omnibus):                  0.698   Jarque-Bera (JB):                0.734\n","Skew:                          -0.005   Prob(JB):                        0.693\n","Kurtosis:                       2.984   Cond. No.                         1.01\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"]}]},{"cell_type":"markdown","source":["Question 3-2:\n","From the perspective of machine learning, code the gradient descent method to optimize the error gundtion and get the coeffients.\n","\n","This code uses gradient descent to fit a linear regression model to the same simulated dataset as before. After selecting input and output variables (and make some needed transformation), we initialize hyperparameters, including the learning rate (lr), the number of iterations (iter), an empty list to store the cost at each iteration (cost_lst), an array to store the cost at each iteration (cost_history), and the model coefficients (theta) to random values.\n","\n","Implementing gradient descent: The for loop in the code implements gradient descent to update the model coefficients (theta) at each iteration. The gradients of the cost function with respect to the coefficients are calculated using the formula for the gradient of the mean squared error (MSE) cost function. The coefficients are then updated by subtracting the product of the learning rate and the gradients from the previous coefficients.\n","\n","Calculating the cost function: The code also calculates the value of the cost function at each iteration using the formula for the MSE cost function. The cost function measures the difference between the predicted values and the actual values of the outcome variable, and the goal of the gradient descent algorithm is to minimize this difference.\n","\n","Gradient descent is an iterative optimization algorithm that is used to find the values of the model coefficients that minimize the cost function. It works by taking small steps in the direction of the steepest descent of the cost function, which is given by the negative gradient. The learning rate is a hyperparameter that determines the step size taken at each iteration, and the number of iterations determines the maximum number of steps taken by the algorithm.\n","\n","The error function, also known as the cost function, is a measure of the difference between the predicted values and the actual values of the outcome variable. In linear regression, the most common error function is the mean squared error (MSE) cost function, which calculates the average squared difference between the predicted and actual values of the outcome variable. The goal of the gradient descent algorithm is to minimize the value of the cost function by updating the model coefficients at each iteration. By minimizing the cost function, we are able to find the values of the model coefficients that best fit the data."],"metadata":{"id":"-OzxPlenb2gC"}},{"cell_type":"code","source":["X = data.iloc[:, 0:2] # 包含之前創造出的data裡面的y和x1\n","y = data.iloc[:, -1].to_numpy()\n","X_new = np.c_[np.ones((len(X),1)),X]\n","y_new = np.reshape(y, (len(y), 1)) \n","lr = 0.01\n","iter = 1000\n","cost_lst = []\n","cost_history = np.zeros(iter)\n","theta = np.random.randn(3,1)\n","\n","for i in range(iter):\n","    gradients = 2/len(X) * X_new.T.dot(X_new.dot(theta) - y_new)\n","    theta -= lr * gradients\n","    predictions = X_new.dot(theta)\n","    cost_history[i] = (1/2*len(y_new)) * np.sum(np.square(predictions-y_new))\n","\n","theta = list(theta)\n","print('Theta0:   {:0.3f}\\nTheta1:   {:0.3f}\\nTheta2:   {:0.3f}'.format(theta[0][0],theta[1][0],theta[2][0]))\n","print(np.array([num for i,num in enumerate(cost_history) if i % 30 == 0 ]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GamKiqwz8YL6","executionInfo":{"status":"ok","timestamp":1678559549171,"user_tz":-480,"elapsed":2767,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"c893b97f-8941-462b-9c82-046958b2a85a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Theta0:   -0.555\n","Theta1:   0.374\n","Theta2:   -0.934\n","[5.11359464e+09 2.20797431e+09 1.44115092e+09 1.20214896e+09\n"," 1.12156109e+09 1.08933948e+09 1.07259151e+09 1.06139140e+09\n"," 1.05266242e+09 1.04538113e+09 1.03914907e+09 1.03376603e+09\n"," 1.02910156e+09 1.02505533e+09 1.02154408e+09 1.01849669e+09\n"," 1.01585175e+09 1.01355609e+09 1.01156357e+09 1.00983416e+09\n"," 1.00833311e+09 1.00703027e+09 1.00589947e+09 1.00491799e+09\n"," 1.00406611e+09 1.00332672e+09 1.00268496e+09 1.00212794e+09\n"," 1.00164448e+09 1.00122486e+09 1.00086064e+09 1.00054452e+09\n"," 1.00027014e+09 1.00003200e+09]\n"]}]},{"cell_type":"markdown","source":["This code creates a scatter plot of the cost function at each iteration of the gradient descent algorithm. The x-axis represents the number of iterations, and the y-axis represents the value of the cost function. The scatter plot can help us understand the behavior of the gradient descent algorithm and how quickly it converges to the optimal values of the model coefficients.\n","\n","The scatter plot show a decreasing trend in the cost function over the number of iterations, as the gradient descent algorithm updates the model coefficients to minimize the cost function. The rate of decrease in the cost function will depend on the learning rate and the number of iterations."],"metadata":{"id":"l9b-9weodmdJ"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fig,ax = plt.subplots(figsize=(12,8))\n","ax.set_ylabel('J(Theta)')\n","ax.set_xlabel('Iterations')\n","_=ax.plot(range(1000),cost_history,'b.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"VnYaWtDo8bKi","executionInfo":{"status":"ok","timestamp":1678559552964,"user_tz":-480,"elapsed":1145,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"e3ff15ba-3866-4e25-9c60-e6be72fd761d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x576 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAscAAAHrCAYAAAAjcDD+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAikElEQVR4nO3de5RlZ1kn4N+bzo17hERAIDRihIUgxGkdChimpB0GAbmIM4hoVHAaxxFBZQV0Zi3WuNQ26mgYrzQGTEYGxwG5CIqyWoqAFEhCIEIiwmBQkJhAAINgOul888feRSqd6k7X5Zx9ztnPs1avXedS57ydvU7nV1+9+/2qtRYAACA5YegCAABgVgjHAADQE44BAKAnHAMAQE84BgCAnnAMAAC9mQvHVfXKqrqmqj50HM+9f1UdrKrLq2qlqu47jRoBAFhMMxeOk/xukicc53N/OclFrbVvTPIzSfZPqigAABbfzIXj1trFSa5bf19VPbCq3lpVl1bVO6vqwf1DD0ny5/3Xb0/y1CmWCgDAgpm5cHwUB5I8v7X2r5K8KMlv9vd/MMl39l8/PcldquoeA9QHAMACOHHoAm5PVd05yaOS/N+qWrv7lP74oiS/XlU/kOTiJJ9KcnjaNQIAsBhmPhynW93+fGvtEUc+0Fr7h/Qrx32IfkZr7fNTrQ4AgIUx820VrbV/SvK3VfUfkqQ6D++/Pr2q1v4OP5XklQOVCQDAApi5cFxVr0mymuRBVfXJqnpukmcneW5VfTDJh3PLhXfLST5SVX+T5J5Jfm6AkgEAWBDVWhu6BgAAmAkzt3IMAABDEY4BAKA3U9MqTj/99LZ79+6hywAAYIFdeumln2mtnbHRYzMVjnfv3p1LLrlk6DIAAFhgVfWJoz2mrQIAAHrCMQAA9IRjAADoCccAANATjgEAoCccAwBATzgGAICecAwAAD3hGAAAesIxAAD0hGMAAOgJxwAA0BOOAQCgJxwDAEBPOAYAgJ5wDAAAvdGH49XVZP/+7ggAwLidOHQBQ1pdTfbuTQ4dSk4+OTl4MFlaGroqAACGMuqV45WVLhgfPtwdV1aGrggAgCGNOhwvL3crxrt2dcfl5aErAgBgSKNuq1ha6lopVla6YKylAgBg3EYdjpMuEAvFAAAkI2+rAACA9YRjAADoCccAANCbaM9xVV2V5Pokh5Pc1FrbM8n3AwCA7ZjGBXnf2lr7zBTeBwAAtkVbBQAA9CYdjluSP6uqS6tq34TfCwAAtmXSbRWPaa19qqq+OsnbquqvW2sXr39CH5r3JcmZZ5454XIAAODoJrpy3Fr7VH+8Jsnrk3zLBs850Frb01rbc8YZZ0yyHAAAOKaJheOqulNV3WXt6ySPT/KhSb0fAABs1yTbKu6Z5PVVtfY+/7u19tYJvh8AAGzLxMJxa+3jSR4+qdcHAICdZpQbAAD0hGMAAOgJxwAA0BOOAQCgJxwDAEBPOAYAgJ5wDAAAPeEYAAB6wjEAAPSE4ySrq8n+/d0RAIDxmtj20fNidTXZuzc5dCg5+eTk4MFkaWnoqgAAGMLoV45XVrpgfPhwd1xZGboiAACGMvpwvLzcrRjv2tUdl5eHrggAgKGMvq1iaalrpVhZ6YKxlgoAgPEafThOukAsFAMAMPq2CgAAWCMcAwBATzgGAICecAwAAD3hGAAAesIxAAD0hGMAAOgJxwAA0BOOAQCgJxwDAEBPOAYAgJ5wDAAAPeEYAAB6wjEAAPSEYwAA6AnHSVZXk/37uyMAAON14tAFDG11Ndm7Nzl0KDn55OTgwWRpaeiqAAAYwuhXjldWumB8+HB3XFkZuiIAAIYy+nC8vNytGO/a1R2Xl4euCACAoYy+rWJpqWulWFnpgrGWCgCA8Rp9OE66QCwUAwAw+rYKAABYIxwDAEBPOAYAgJ5wDAAAPeEYAAB6wjEAAPSEYwAA6AnHAADQE44BAKAnHAMAQE84BgCAnnAMAAA94bi3uprs398dAQAYpxOHLmAWrK4me/cmhw4lJ5+cHDyYLC0NXRUAANNm5TjJykoXjA8f7o4rK0NXBADAEITjJMvL3Yrxrl3dcXl56IoAABiCtop0LRQHD3YrxsvLWioAAMZKOO4tLQnFAABjp60CAAB6wjEAAPSEYwAA6AnHAADQE44BAKAnHAMAQE84BgCAnnAMAAA94RgAAHrCMQAA9ITj3upqsn9/dwQAYJxOHLqAWbC6muzdmxw6lJx8cnLwYLK0NHRVAABMm5XjJCsrXTA+fLg7rqwMXREAAEMQjpMsL3crxrt2dcfl5aErAgBgCNoq0rVQHDzYrRgvL2upAAAYK+G4t7QkFAMAjJ22CgAA6AnHAADQE44BAKAnHAMAQE84BgCAnnAMAAA94RgAAHrC8Tqrq8n+/d0RAIDxsQlIb3U12bs3OXSo20L64EGbggAAjI2V497KSheMDx/ujisrQ1cEAMC0Cce95eVuxXjXru64vDx0RQAATJu2it7SUtdKsbLSBWMtFQAA4yMcr7O0JBQDAIyZtgoAAOgJxwAA0BOOAQCgJxwDAEBv4uG4qnZV1WVV9eZJvxcAAGzHNFaOX5Dkyim8DwAAbMtEw3FV3TfJk5L8ziTfBwAAdsKkV47PT3Jukpsn/D47ZnU12b+/OwIAMC4T2wSkqp6c5JrW2qVVtXyM5+1Lsi9JzjzzzEmVc1xWV5O9e5NDh7otpA8etCkIAMCYTHLl+NFJnlJVVyX5/SSPq6rfO/JJrbUDrbU9rbU9Z5xxxgTLuX0rK10wPny4O66sDFoOAABTNrFw3Fr7qdbafVtru5N8d5I/b61976TebycsL3crxrt2dcfl5aErAgBgmibWVjGPlpa6VoqVlS4Ya6kAABiXqYTj1tpKkpVpvNd2LS0JxQAAY2WHPAAA6AnHAADQE44BAKAnHAMAQE84BgCAnnB8BNtHAwCMlznH69g+GgBg3Kwcr2P7aACAcROO17F9NADAuGmrWMf20QAA4yYcH8H20QAA46WtAgAAesIxAAD0hGMAAOgJxwAA0BOOAQCgJxxvwBbSAADjZJTbEWwhDQAwXlaOj2ALaQCA8RKOj2ALaQCA8dJWcQRbSAMAjJdwvAFbSAMAjJO2CgAA6AnHAADQE44BAKAnHAMAQE843oAd8gAAxsm0iiPYIQ8AYLysHB/BDnkAAOMlHB/BDnkAAOOlreIIdsgDABgv4XgDdsgDABgnbRUAANATjgEAoCccAwBATzgGAICecHwUdskDABgf0yo2YJc8AIBxsnK8AbvkAQCMk3C8AbvkAQCMk7aKDdglDwBgnITjo7BLHgDA+GirAACAnnAMAAA94RgAAHrC8THYCAQAYFxckHcUNgIBABgfK8dHYSMQAIDxEY6PwkYgAADjo63iKGwEAgAwPsLxMdgIBABgXLRVAABATzgGAICecAwAAD3h+BhsAgIAMC4uyDsKm4AAAIyPleOjsAkIAMD4CMdHYRMQAIDx0VZxFDYBAQAYH+H4GGwCAgAwLtoqAACgJxwDAEBPOAYAgJ5wfDtsBAIAMB4uyDsGG4EAAIyLleNjsBEIAMC4CMfHYCMQAIBxud22iqo6IcnDk3xNki8n+VBr7ZpJFzYLbAQCADAuRw3HVfXAJC9O8m1JPprk2iSnJvn6qvpSkpcnubC1dvM0Ch2KjUAAAMbjWCvHP5vkt5I8r7XW1j9QVV+d5HuSfF+SCydXHgAATM9Rw3Fr7VnHeOyaJOdPoiAAABjKcY1yq6qHJnlIuraKJElr7aJJFTVrVlf1HQMAjMHxXJD30iTL6cLxHyf59iTvSjKKcGzWMQDAeBzPKLfvSrI3ydWttR9MN7nibhOtaoaYdQwAMB7HE46/3E+kuKmq7prkmiT3m2xZs8OsYwCA8TienuNLquq0JK9IcmmSLyZZnWRRs8SsYwCA8agjprQd+8lVu5PctbV2+SSK2bNnT7vkkksm8dIAAJAkqapLW2t7Nnrsdtsqqurg2tettataa5evvw8AABbFsXbIOzXJHZOcXlVflaT6h+6a5D5TqA0AAKbqWD3Hz0vywiRfk+T96+7/pyS/PsGaZo45xwAA43CsHfJeluRlVfX81tqvTbGmmWLOMQDAeBzPKLdXVtV/q6oDSVJVZ1XVkydc18ww5xgAYDyOKxwnOZTkUf3tTyX52YlVNGPMOQYAGI/jmXP8wNbaM6vqWUnSWvtSVdXtfdOiMOcYAGA8jiccH6qqOyRpSVJVD0xyw0SrmjFLS0IxAMAYHE84fmmStya5X1W9Osmjk/zAJIsCAIAh3G44bq29raren+SR6WYdv6C19pmJVzZjjHMDAFh8x7NynCSnJvlc//yHVFVaaxcf6xv6TUQuTnJK/32vba29dDvFDsU4NwCAcbjdcFxV5yV5ZpIPJ7m5v7ulC77HckOSx7XWvlhVJyV5V1X9SWvtPdspeAgbjXMTjgEAFs/xrBw/LcmDWmubugivtdaSfLG/eVL/p22quhmxNs5tbeXYODcAgMV0POH44+mC7aYnVFTVriSXJvm6JL/RWnvvZl9jFhjnBgAwDkcNx1X1a+lWer+U5ANVdTDrAnJr7cdu78Vba4eTPKKqTkvy+qp6aGvtQ0e8z74k+5LkzDPP3MrfYSqMcwMAWHzHWjm+pD9emuRN23mT1trnq+rtSZ6Q5ENHPHYgyYEk2bNnz1y2XQAAsBiOFY6/tbX2A1t94ao6I8mNfTC+Q5J/l+S8rb7e0IxyAwBYfMcKx9+4zde+d5IL+77jE5L8QWvtzdt8zUEY5QYAMA7HCsd3rKqz0238cRuttfcf64Vba5cnOXsbtc0Mo9wAAMbhWOH4Pkn+RzYOxy3J4yZS0Qwyyg0AYByOFY4/1lobTQA+FqPcAADG4Xi3jx49o9wAABbfCcd47MVTqwIAAGbAscLx86vqO6rqpCMfqKqvraqfqarnTLC2mbO6muzf3x0BAFg8x2qr+E9JfiLJ+VV1XZJrk9whye4kH0u3HfQbJl3grDDODQBg8R01HLfWrk5ybpJzq2p3knsl+XKSv2mtfXk65c0O49wAABbfUcNxVV2fbmTbV+5au11VNyT5f0n+a2vt4EQrnBHGuQEALL5jrRzf5WiP9bvePTTJq/vjwjPODQBg8W1plFtr7XCSD1bVr+1wPTPNODcAgMV2rGkVt6u19vKdKgQAAIa2rXA8Rsa5AQAsLjvkbYJxbgAAi83K8SZsNM4NAIDFIRxvwto4t127jHMDAFhE2io2wTg3AIDFJhxvknFuAACLS1vFJplWAQCwuKwcb4JpFQAAi83K8SaYVgEAsNiE400wrQIAYLFpq9gE0yoAABabcLxJplUAACwubRVbYGIFAMBisnK8SSZWAAAsLivHm2RiBQDA4hKON8nECgCAxaWtYpNMrAAAWFzC8RaYWAEAsJi0VWyBaRUAAIvJyvEmmVYBALC4rBxvkmkVAACLSzjeJNMqAAAWl7aKTTKtAgBgcQnHW2BaBQDAYtJWsUUmVgAALB4rx1tgYgUAwGKycrwFJlYAACwm4XgLTKwAAFhM2iq2wMQKAIDFJBxv0VogXmupEJABAOafcLxFLsoDAFg8eo63yEV5AACLRzjeIhflAQAsHm0VW+SiPACAxSMcb4NtpAEAFou2im2whTQAwGKxcrxFplUAACweK8dbZFoFAMDiEY63yLQKAIDFo61ii0yrAABYPMLxNthCGgBgsQjH2+CiPACAxaLneBtclAcAsFiE421wUR4AwGLRVrENLsoDAFgsVo4BAKBn5XgbXJAHALBYrBxvgwvyAAAWi3C8DS7IAwBYLNoqtmHtgryLLhq6EgAAdoKV4x1w4YXJK17R9R+vrg5dDQAAWyUcb5O+YwCAxSEcb5O+YwCAxaHneJtsBAIAsDiE4x2wFojXWioEZACA+SQc7wCbgQAALAY9xzvARXkAAItBON4BLsoDAFgM2ip2wNJScv75yetelzzjGVoqAADmlXC8A1ZXkxe+sGupeOc7k4c9TEAGAJhH2ip2gJ5jAIDFIBzvAD3HAACLQVvFDljbCOSii4auBACA7bByvIMuvDB5xSu6mcerq0NXAwDAZgnHO0TfMQDA/BOOd4i+YwCA+afneIfoOwYAmH9WjneYvmMAgPklHO8gfccAAPNNON5B+o4BAOabnuMdtLSUnH9+8rrXJc94hi2kAQDmjXC8g1ZXkxe+sGupeOc7k4c9TEAGAJgn2ip2kJ5jAID5JhzvoLWe4xNOSKqSe9xj6IoAANgM4XgHrfUc79qV3Hxz12JhnBsAwPwQjnfYZz/bBeObb9ZaAQAwbyYWjqvqflX19qq6oqo+XFUvmNR7zRLj3AAA5tckp1XclOQnW2vvr6q7JLm0qt7WWrtigu85OOPcAADm18TCcWvt00k+3X99fVVdmeQ+SRY6HBvnBgAwv6bSc1xVu5OcneS903i/IRnnBgAwvyYejqvqzklel+SFrbV/2uDxfVV1SVVdcu211066nIkzzg0AYH5NNBxX1UnpgvGrW2t/uNFzWmsHWmt7Wmt7zjjjjEmWMxXGuQEAzK9JTquoJBckubK19iuTep9ZZJwbAMB8muTK8aOTfF+Sx1XVB/o/T5zg+80M49wAAObTJKdVvCtJTer1Z9nSUnLwYHLRRUNXAgDAZtghb4IuvDB5xSuSvXv1HQMAzAPheEKMdAMAmD/C8YQsL3c9x1XdUd8xAMDsE44nqOrWRwAAZptwPCErK8lNNyWtdUdtFQAAs084nhA75QEAzB/heELslAcAMH+E4wmyUx4AwHwRjifIxAoAgPkiHE+YiRUAAPNDOJ6g9RMrDh2ynTQAwKwTjidora0i6QLyq17lojwAgFkmHE/Q0lLynOfc0lJh3jEAwGwTjifsnHOSU0817xgAYB4IxxNm3jEAwPwQjqfAvGMAgPkgHE+BeccAAPNBOJ4S844BAGafcDwF5h0DAMwH4XgKzDsGAJgPwvEUrM07XnPjjS7KAwCYRcLxlJx99i1f33yzeccAALNIOJ6Sz3622wgk6Y6f/eyw9QAAcFvC8ZQsLyennNIF4xNOsHIMADCLhOMpsVMeAMDsE46naP1Oef/yL0a6AQDMGuF4iox0AwCYbcLxFBnpBgAw24TjKTPSDQBgdgnHU7Z+pFtVctllw9YDAMAthOMpW15OTjyx+1rfMQDAbBGOp0zfMQDA7BKOB6DvGABgNgnHA9B3DAAwm4TjAeg7BgCYTcLxANb6jqu624cO2S0PAGAWCMcDOeec5KSTuq9bSy64wOoxAMDQhOOBLC0lT3ziLbdvvNHqMQDA0ITjAd3rXre+ffXVw9QBAEBHOB7Q+taKJPmTP9FaAQAwJOF4QEtLyXOf68I8AIBZIRwPzIV5AACzQzgemAvzAABmh3A8A1yYBwAwG4TjGXDkhXlveYvWCgCAIQjHM2BpKXnSk265feONyS/+4nD1AACMlXA8I45srfijP7J6DAAwbcLxjDjnnGTXrltu33yzC/MAAKZNOJ4RS0vJb/7mLQHZWDcAgOkTjmfIvn3Jd3zHLbf1HgMATJdwPGOO7D1+05usHgMATItwPGPOOSc5Yd1Zuflmq8cAANMiHM+YpaXkKU+59X1vfGNy4MAw9QAAjIlwPIPOPffWkytaS370R7VXAABMmnA8g9YmV6xvr7jppmRlZbCSAABGQTieUfv2JS960S23W0s+/OHh6gEAGAPheIaddtqtb7/61cmLXzxIKQAAoyAcz7Dl5Vu3ViTJL/2Si/MAACZFOJ5hS0u3bq1IuvaKH/kRF+cBAEyCcDzjzjuvm16x3uHDZh8DAEyCcDwHzjsvedrTbn2fnfMAAHaecDwnzj33tjvn/dAPCcgAADtJOJ4TG+2cd8UVyb/9twIyAMBOEY7nyJE75yXJjTdaQQYA2CnC8RxZ2zmv6tb3W0EGANgZwvGc2bcv+e3fvm1AvvHG5CUvGaYmAIBFIRzPoaMF5IsvtoIMALAdwvGcWgvIR7r44uQxj7GLHgDAVgjHc2zfvttuEJJ0Y95++IcFZACAzRKO59xGO+gl3TbTz3te8uIXT78mAIB5JRwvgPPOS17+8tv2ICfdNtOPeIQ+ZACA4yEcL4i1HuQTNjijH/xg8uhHW0UGALg9wvEC2bcvede7ksc+9raPtdatIt/73snTn24lGQBgI8LxgllaSt7xjuTZz9748auvTt7whuRRjxKSAQCOJBwvqN/7va4P+f73P/pz1kKy2cgAAB3heIHt25dcddXG0yzWu/jiLiQ/4AHGvwEA4yYcj8B55yXvfvfGvcjrXXVVN/7tHvdIvuEbBGUAYHyE45FY60V+97uTpz3t2M+97rrkiiu6oHzveydnn5085CF6lAGAxVettaFr+Io9e/a0Sy65ZOgyRmF1tZte8Z73dBfpbca97pWcemo3P/ncc7vgDQAwL6rq0tbang0fE445cCD5+Z9PPvGJrX3/ve7V/fnc57qNSIRmAGCWCcccl+2sJm/krLOSQ4e6wHzaaV14vtOdkhe8oLtYEABgCMIxm7YWlD/ykeSmm5KPfnRnX//ud0/uetcuNN9wQ3LKKbesPK/d96AHWYEGAHaecMy2ra4mF13UXaj3iU8k11/fXbg3DWs9zmurz+sD9JGh2uo0AHB7hGMm4sCB5Pzzky9/+ZZgOs3QfHvWr04fT6je6OuTT06e+1xBGwAWiXDMVB04kFxwQddvvD5oXn31zvQyD+FoQftoXx9vAD/zzG5M3jnnaB8BgGkRjpkZa73Ml1129CB50kk73+M8D846KznxxONf1d7MCvhG32dVHICxEo6ZO0f2OB9vOJzn1emh3Oc+XSifdBjfynOtrAMwCYOE46p6ZZInJ7mmtfbQ4/ke4ZidsNHq9FbC2lhXsGfVRqMBhwzuk3oPU1oAJm+ocPzYJF9McpFwzLy6vaC9nUB0ww1WuTm63bsnE8AX8YeKWa7NDzwwmwZrq6iq3UneLBzDxtbPkz7llOn9j/3665NPfnLAvziM0KL8wDPLP4yobb5qG/KHx2OF4xOnWwqw3tJS8vrXD/PeR5sqMiv/0FpZZ9FcddXQFcDsufLK5C1vSd7xjtn57crg4biq9iXZlyRnnnnmwNXAeOzbN/uTKo5cWZ+V4D6J99DjDozVjTcmKyvC8Ve01g4kOZB0bRUDlwPMkCFX1oewfkrLtdfOTnCf5R8qZrk2P/DA8TnppGR5eegqbjF4OAags7Q0Oysn7IxF/IFnVn8YUdv81TarF6xOLBxX1WuSLCc5vao+meSlrbULJvV+ADBr/MAD82di4bi19qxJvTYAAEzCCUMXAAAAs0I4BgCAnnAMAAA94RgAAHrCMQAA9IRjAADoCccAANATjgEAoCccAwBATzgGAICecAwAAD3hGAAAesIxAAD0hGMAAOgJxwAA0KvW2tA1fEVVXZvkEwO89elJPjPA+zJdzvM4OM/j4DwvPud4HIY6z/dvrZ2x0QMzFY6HUlWXtNb2DF0Hk+U8j4PzPA7O8+JzjsdhFs+ztgoAAOgJxwAA0BOOOweGLoCpcJ7HwXkeB+d58TnH4zBz51nPMQAA9KwcAwBAb/ThuKqeUFUfqaqPVdVLhq6Hramq+1XV26vqiqr6cFW9oL//7lX1tqr6aH/8qv7+qqr/2Z/3y6vqm4b9G7AZVbWrqi6rqjf3tx9QVe/tz+f/qaqT+/tP6W9/rH9896CFc9yq6rSqem1V/XVVXVlVSz7Pi6eqfrz/N/tDVfWaqjrV53n+VdUrq+qaqvrQuvs2/fmtqu/vn//Rqvr+adU/6nBcVbuS/EaSb0/ykCTPqqqHDFsVW3RTkp9srT0kySOT/Jf+XL4kycHW2llJDva3k+6cn9X/2Zfkt6ZfMtvwgiRXrrt9XpJfba19XZLPJXluf/9zk3yuv/9X++cxH16W5K2ttQcneXi68+3zvECq6j5JfizJntbaQ5PsSvLd8XleBL+b5AlH3Lepz29V3T3JS5P86yTfkuSla4F60kYdjtP9x/5Ya+3jrbVDSX4/yVMHroktaK19urX2/v7r69P9j/Q+6c7nhf3TLkzytP7rpya5qHXek+S0qrr3dKtmK6rqvkmelOR3+tuV5HFJXts/5cjzvHb+X5tkb/98ZlhV3S3JY5NckCSttUOttc/H53kRnZjkDlV1YpI7Jvl0fJ7nXmvt4iTXHXH3Zj+//z7J21pr17XWPpfkbblt4J6IsYfj+yT5+3W3P9nfxxzrf9V2dpL3Jrlna+3T/UNXJ7ln/7VzP7/OT3Jukpv72/dI8vnW2k397fXn8ivnuX/8C/3zmW0PSHJtklf17TO/U1V3is/zQmmtfSrJLyf5u3Sh+AtJLo3P86La7Od3sM/12MMxC6aq7pzkdUle2Fr7p/WPtW40i/Esc6yqnpzkmtbapUPXwkSdmOSbkvxWa+3sJP+cW34Fm8TneRH0vyJ/arofhr4myZ0ypZVBhjXrn9+xh+NPJbnfutv37e9jDlXVSemC8atba3/Y3/2Pa79e7Y/X9Pc79/Pp0UmeUlVXpWuDely63tTT+l/LJrc+l185z/3jd0vy2WkWzJZ8MsknW2vv7W+/Nl1Y9nleLN+W5G9ba9e21m5M8ofpPuM+z4tps5/fwT7XYw/H70tyVn9l7MnpLgR408A1sQV939kFSa5srf3KuofelGTtCtfvT/LGdfef018l+8gkX1j36x5mVGvtp1pr922t7U73ef3z1tqzk7w9yXf1TzvyPK+d/+/qnz+zqxV0WmtXJ/n7qnpQf9feJFfE53nR/F2SR1bVHft/w9fOs8/zYtrs5/dPkzy+qr6q/y3D4/v7Jm70m4BU1RPT9TDuSvLK1trPDVsRW1FVj0nyziR/lVt6UX86Xd/xHyQ5M8knkvzH1tp1/T/Ev57uV3hfSvKDrbVLpl44W1ZVy0le1Fp7clV9bbqV5LsnuSzJ97bWbqiqU5P8r3Q96Ncl+e7W2scHKplNqKpHpLvo8uQkH0/yg+kWdHyeF0hV/fckz0w3ceiyJD+Urq/U53mOVdVrkiwnOT3JP6abOvGGbPLzW1XPSff/8iT5udbaq6ZS/9jDMQAArBl7WwUAAHyFcAwAAD3hGAAAesIxAAD0hGMAAOgJxwBTUFVf7I+7q+p7dvi1f/qI2+/eydcHGBPhGGC6difZVDhet1vY0dwqHLfWHrXJmgDoCccA0/ULSf5NVX2gqn68qnZV1S9V1fuq6vKqel7SbXJSVe+sqjel2zUsVfWGqrq0qj5cVfv6+34hyR3613t1f9/aKnX1r/2hqvqrqnrmutdeqarXVtVfV9Wr+0H8qapfqKor+lp+eer/dQAGdnurEQDsrJek39kvSfqQ+4XW2jdX1SlJ/qKq/qx/7jcleWhr7W/728/pd5S6Q5L3VdXrWmsvqaofba09YoP3+s4kj0jy8HQ7Vb2vqi7uHzs7yTck+Yckf5Hk0VV1ZZKnJ3lwa61V1Wk7+1cHmH1WjgGG9fgk51TVB9Jtd36PJGf1j/3lumCcJD9WVR9M8p4k91v3vKN5TJLXtNYOt9b+Mck7knzzutf+ZGvt5iQfSNfu8YUk/5Lkgqr6znRbuQKMinAMMKxK8vzW2iP6Pw9ora2tHP/zV55UtZzk25IstdYenuSyJKdu431vWPf14SQnttZuSvItSV6b5MlJ3rqN1weYS8IxwHRdn+Qu627/aZL/XFUnJUlVfX1V3WmD77tbks+11r5UVQ9O8sh1j9249v1HeGeSZ/Z9zWckeWySvzxaYVV15yR3a639cZIfT9eOATAqeo4BpuvyJIf79ojfTfKydC0N7+8virs2ydM2+L63Jvnhvi/4I+laK9YcSHJ5Vb2/tfbsdfe/PslSkg8maUnOba1d3YfrjdwlyRur6tR0K9o/saW/IcAcq9ba0DUAAMBM0FYBAAA94RgAAHrCMQAA9IRjAADoCccAANATjgEAoCccAwBATzgGAIDe/wdIe6V7zl1d4wAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Discussion:\n","\n","In general, the iterative errors should decrease over the course of the algorithm, reflecting an improvement in the fit of the model to the data. The searching path in the domain of the error function may be complex, with the algorithm potentially moving in a zig-zag pattern as it attempts to converge to the optimal values of the model coefficients. Visualizing the error function and the path taken by the algorithm can be useful in understanding the behavior of the algorithm and identifying potential issues such as local minima or slow convergence\n","\n","to be honest, I am not sure whether these two outcome is comparable or not, but I think the features of each algorithms show great results, I think they are not very unlike."],"metadata":{"id":"nKD-y_UKdy9E"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}